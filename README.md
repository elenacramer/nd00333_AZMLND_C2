# Training-Deploying-Consuming ML models using AzureML

In this project we will demonstrate an end-to-end ML example, that is, from model training to model deployment to consuming a model. Although we will train a model, our focus will be on deployment and consumption.  

The data sets is the same as for the previous project, i.e. the data set contains information such as age, marital status, job, education ect. of bank clients and the goal is to predict whether a client will subscribe to a term deposit or not, described by the variable "y". 

![dataset](https://github.com/elenacramer/nd00333_AZMLND_C2/blob/master/screenshots/registered_dataset.png)

Two approaches where applied. First one using Automated ML and the second using a Pipeline. Both approaches require loading the data set. 

## Automated ML 
The required steps for training, deploying and consuming a model using Automated ML:
- **Create a new Automated ML run & experiment** 
	- Configure a new compute cluster
		- Select Virtual Machine, the minimum and maximum number of nodes
	- Select best model for deployment
- **Deploy the best model** 
	- Enable Authentication and use Azure Container Instance (ACI)
	- Enable Application Insights
		- Running the script *logs.py* enables to the view the logs 
- **Consume deployed model**
	- Using *Swagger* ( a tool that helps build, document, and consume RESTful web services)
		- Download the *swagger.json* file (can be found under the Endpoint section -> deployed model)
		- Make sure it is in the same directory as *swagger.sh* and *serve.py*
		-  Run swagger.sh and sesrve.py 
	- Using a *deployed service via an HTTP API* ( that is a URL that is exposed over the network so that interaction with a trained model can happen via HTTP requests)
		-  To interact with the endpoint, we use the script *endpoint.py* (i.e. initiates an input requests via an HTTP POST and GET requests)
			- The script contains two sets of data , i.e. information about two clients we would like to make predictions on 
			- To run the script the "scoring uri" and a "key" must be provided (generated by the deployed model)
  
 ### Key Steps 
- Experiment is completed
![experiment_completed](https://github.com/elenacramer/nd00333_AZMLND_C2/blob/master/screenshots/completed_AutomatedML_run.png)

-Models of the Automated ML run
![models](https://github.com/elenacramer/nd00333_AZMLND_C2/blob/master/screenshots/Automated_ML_models.png)


- Best model of the completed Automated ML run
![best_model](https://github.com/elenacramer/nd00333_AZMLND_C2/blob/master/screenshots/AutomatedML_best_model.png)

- Application Insights is enabled
![app_insights](https://github.com/elenacramer/nd00333_AZMLND_C2/blob/master/screenshots/AutomatedML_app_insights.png)

- Logs (running *logs.py*)
![Logs](https://github.com/elenacramer/nd00333_AZMLND_C2/blob/master/screenshots/running_logs_py.png)

- Swagger running on localhost showing the HTTP API methods 
![swagger](https://github.com/elenacramer/nd00333_AZMLND_C2/blob/master/screenshots/swagger.png)

- Model predictions for the particular clients (running endpoint.py) 
![model_pred](https://github.com/elenacramer/nd00333_AZMLND_C2/blob/master/screenshots/model_pred.png)

## Architectural Diagram
*TODO*: Provide an architectual diagram of the project and give an introduction of each step. An architectural diagram is an image that helps visualize the flow of operations from start to finish. In this case, it has to be related to the completed project, with its various stages that are critical to the overall flow. For example, one stage for managing models could be "using Automated ML to determine the best model". 

## Key Steps
*TODO*: Write a short discription of the key steps. Remeber to include all the screenshots required to demonstrate key steps. 

## Screen Recording
*TODO* Provide a link to a screen recording of the project in action. Remember that the screencast should demonstrate:

## Standout Suggestions
*TODO (Optional):* This is where you can provide information about any standout suggestions that you have attempted.
